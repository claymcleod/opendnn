{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/Theano-0.8.0.dev0-py2.7.egg/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "Threshold!\n",
      "finished.\n",
      "Beginning training...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "60000/60000 [==============================] - 86s - loss: 1.0977 - acc: 0.7000 - val_loss: 0.2428 - val_acc: 0.9282\n",
      "Epoch 00000: val_loss improved from inf to 0.24283, saving model to mnist_weights_pap\n",
      "Epoch 2/500\n",
      "60000/60000 [==============================] - 86s - loss: 0.4029 - acc: 0.8763 - val_loss: 0.1709 - val_acc: 0.9480\n",
      "Epoch 00001: val_loss improved from 0.24283 to 0.17086, saving model to mnist_weights_pap\n",
      "Epoch 3/500\n",
      "60000/60000 [==============================] - 85s - loss: 0.3143 - acc: 0.9029 - val_loss: 0.1502 - val_acc: 0.9568\n",
      "Epoch 00002: val_loss improved from 0.17086 to 0.15017, saving model to mnist_weights_pap\n",
      "Epoch 4/500\n",
      "60000/60000 [==============================] - 84s - loss: 0.2786 - acc: 0.9142 - val_loss: 0.1349 - val_acc: 0.9584\n",
      "Epoch 00003: val_loss improved from 0.15017 to 0.13487, saving model to mnist_weights_pap\n",
      "Epoch 5/500\n",
      "60000/60000 [==============================] - 83s - loss: 0.2555 - acc: 0.9207 - val_loss: 0.1284 - val_acc: 0.9616\n",
      "Epoch 00004: val_loss improved from 0.13487 to 0.12835, saving model to mnist_weights_pap\n",
      "Epoch 6/500\n",
      "60000/60000 [==============================] - 84s - loss: 0.2411 - acc: 0.9262 - val_loss: 0.1131 - val_acc: 0.9657\n",
      "Epoch 00005: val_loss improved from 0.12835 to 0.11309, saving model to mnist_weights_pap\n",
      "Epoch 7/500\n",
      "60000/60000 [==============================] - 83s - loss: 0.2261 - acc: 0.9306 - val_loss: 0.1144 - val_acc: 0.9658\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 8/500\n",
      "60000/60000 [==============================] - 84s - loss: 0.2203 - acc: 0.9325 - val_loss: 0.1041 - val_acc: 0.9664\n",
      "Epoch 00007: val_loss improved from 0.11309 to 0.10410, saving model to mnist_weights_pap\n",
      "Epoch 9/500\n",
      "60000/60000 [==============================] - 85s - loss: 0.2088 - acc: 0.9348 - val_loss: 0.1005 - val_acc: 0.9686\n",
      "Epoch 00008: val_loss improved from 0.10410 to 0.10047, saving model to mnist_weights_pap\n",
      "Epoch 10/500\n",
      "60000/60000 [==============================] - 85s - loss: 0.1979 - acc: 0.9388 - val_loss: 0.0943 - val_acc: 0.9702\n",
      "Epoch 00009: val_loss improved from 0.10047 to 0.09428, saving model to mnist_weights_pap\n",
      "Epoch 11/500\n",
      "60000/60000 [==============================] - 85s - loss: 0.1973 - acc: 0.9381 - val_loss: 0.0913 - val_acc: 0.9706\n",
      "Epoch 00010: val_loss improved from 0.09428 to 0.09129, saving model to mnist_weights_pap\n",
      "Epoch 12/500\n",
      "60000/60000 [==============================] - 86s - loss: 0.1930 - acc: 0.9395 - val_loss: 0.0903 - val_acc: 0.9705\n",
      "Epoch 00011: val_loss improved from 0.09129 to 0.09032, saving model to mnist_weights_pap\n",
      "Epoch 13/500\n",
      "60000/60000 [==============================] - 106s - loss: 0.1892 - acc: 0.9407 - val_loss: 0.0870 - val_acc: 0.9723\n",
      "Epoch 00012: val_loss improved from 0.09032 to 0.08703, saving model to mnist_weights_pap\n",
      "Epoch 14/500\n",
      "19200/60000 [========>.....................] - ETA: 226s - loss: 0.1807 - acc: 0.9432"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.advanced_activations import Quorum\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.activations import relu\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "af = \"pap\" #pap, relu, thresh, notrain\n",
    "init_fn = \"he_normal\"\n",
    "\n",
    "def pushln(line):\n",
    "    sys.stdout.write(line)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def step(X):\n",
    "    return K.switch(X <= 0, 0, 1)\n",
    "\n",
    "def prepare_input_data(X_train, X_test):\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    return X_train, X_test\n",
    "\n",
    "def prepare_output_data(y_train, y_test):\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    return y_train, y_test\n",
    "\n",
    "def get_af(name):\n",
    "    af = name.lower()\n",
    "    \n",
    "    if af == \"relu\":\n",
    "        return Activation('relu')\n",
    "    elif af == \"pap\":\n",
    "        return Quorum([relu, step], threshold=0.5)\n",
    "    elif af == \"notrain\":\n",
    "        return Quorum([relu, step], trainable=False)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unrecognized activation function: {}\".format(name))\n",
    "\n",
    "def add_convolutional_layers(model, activation_name, n, filter_size, window, \n",
    "                             dropout=0.25, stack_finished=True, input_shape=None):\n",
    "    if input_shape:\n",
    "        model.add(Convolution2D(filter_size, window, window, border_mode=\"same\", \n",
    "                  init=init_fn, input_shape=input_shape))\n",
    "        model.add(get_af(af))\n",
    "        n=n-1\n",
    "        \n",
    "    for i in range(n):\n",
    "        model.add(Convolution2D(filter_size, window, window, border_mode=\"same\", init=init_fn))\n",
    "        model.add(get_af(activation_name))\n",
    "        \n",
    "    if stack_finished:\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "# Script\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = prepare_input_data(X_train, X_test)\n",
    "y_train, y_test = prepare_output_data(y_train, y_test)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 2 x 4 x 3\n",
    "add_convolutional_layers(model, af, 2, 4, 3, input_shape=(1, 28, 28))\n",
    "\n",
    "# 2 x 8 x 3\n",
    "add_convolutional_layers(model, af, 2, 8, 3)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# 1 x 10 x FC\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "pushln(\"Compiling model...\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "pushln(\"finished.\\n\")\n",
    "mc = ModelCheckpoint(\"mnist_weights_\"+af, save_best_only=True, verbose=1)\n",
    "pushln(\"Beginning training...\\n\")\n",
    "hist = model.fit(X_train, y_train, batch_size=128, verbose=1,\n",
    "                        nb_epoch=500, show_accuracy=True,\n",
    "                        validation_data=(X_test, y_test), callbacks=[mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
