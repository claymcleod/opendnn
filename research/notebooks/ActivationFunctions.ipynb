{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting activation functions for DNNs\n",
    "\n",
    "This notebook was created in preparation for my master's thesis. These are the activation functions I will be outlining, as well as their introductions. See the [papers][1] page for the links to the actual papers.\n",
    "\n",
    "**Sigmoid** as presented in [A1]\n",
    "\n",
    "\\begin{equation}\n",
    "S(x) = \\frac{1}{1 + e^{-x}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "**Tanh** as presented in [A1]\n",
    "\n",
    "\\begin{equation}\n",
    "tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
    "\\end{equation}\n",
    "\n",
    "**Softsign** as presented in [A2]\n",
    "\n",
    "\\begin{equation}\n",
    "softsign(x) = \\frac{x}{1 + |x|}\n",
    "\\end{equation}\n",
    "\n",
    "**Rectified Linear Unit (ReLU)** as presented in [A3]\n",
    "\n",
    "\\begin{equation}\n",
    "ReLU(x) =\n",
    "\\begin{cases}\n",
    "x,  & \\text{if $X > 0$} \\\\\n",
    "0, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "**Leaky ReLU (LReLU)/Parametric ReLU (PReLU)** as presented in [A4]/[A5]\n",
    "\n",
    "\\begin{equation}\n",
    "ReLU(x) =\n",
    "\\begin{cases}\n",
    "x,  & \\text{if $X > 0$} \\\\\n",
    "\\alpha x, & \\text{otherwise, }0 \\leq \\alpha \\leq 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "**Exponential Linear Unit (ELU)** as presented in [A6]\n",
    "\n",
    "\\begin{equation}\n",
    "ReLU(x) =\n",
    "\\begin{cases}\n",
    "x,  & \\text{if $X > 0$} \\\\\n",
    "\\alpha (exp(x) - 1), & \\text{otherwise, }0 \\leq \\alpha \\leq 1\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "[1]:https://github.com/claymcleod/opendnn/tree/master/papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softsign(x):\n",
    "    return x / (1 + np.abs(x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.select([x > 0, x <= 0], [x, 0])\n",
    "\n",
    "def lrelu(x, alpha):\n",
    "    return np.select([x > 0, x <= 0], [x, x*alpha])\n",
    "\n",
    "def elu(x, alpha):\n",
    "    return np.select([x > 0, x <= 0], [x, (np.exp(x)-1)*alpha])\n",
    "\n",
    "def plot_fn(fn, legend=None, save_name=None, min_x=-4, max_x=4):\n",
    "    x=np.linspace(min_x, max_x)\n",
    "    \n",
    "    plt.clf()\n",
    "    ax = plt.gca()\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_smart_bounds(True)\n",
    "    ax.spines['bottom'].set_smart_bounds(True)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    \n",
    "    if not isinstance(fn, list):\n",
    "        fn = [fn]\n",
    "    \n",
    "    for f in fn:\n",
    "        plt.plot(x, f(x))\n",
    "        \n",
    "    if legend:\n",
    "        plt.legend(legend, loc=4)\n",
    "        \n",
    "    if save_name:\n",
    "        print(\"Saved to {}\".format(save_name))\n",
    "        plt.savefig(save_name)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "# Uncomment any of these that you like!\n",
    "\n",
    "#plot_fn(sigmoid)\n",
    "#plot_fn(tanh)\n",
    "#plot_fn(softsign)\n",
    "#plot_fn(relu)\n",
    "#plot_fn([sigmoid, tanh, softsign], legend=[\"Logistic\", \"Tanh\", \"Softsign\"], save_name=\"sigmoids\")\n",
    "plot_fn([relu, partial(lrelu, alpha=0.25), partial(lrelu, alpha=0.5), partial(elu, alpha=1)], legend=[\"ReLU\", \"LReLU a=0.25\", \"LReLU a=0.5\", \"ELU a=1.0\"], save_name=\"lrelus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
